{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial News Sentiment Analysis - EDA\n",
    "\n",
    "## Task 1: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.11.0)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/hp/Downloads/Telegram Desktop/10Academy-Week1-FNSPID/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme()\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# List of tickers and their file paths\n",
    "tickers = ['AAPL', 'AMZN', 'GOOG', 'NVDA', 'TSLA', 'META']\n",
    "file_paths = [\n",
    "    'financial-news-sentiment/data/AAPL_historical_data.csv',\n",
    "    'financial-news-sentiment/data/AMZN_historical_data.csv',\n",
    "    'financial-news-sentiment/data/GOOG_historical_data.csv',\n",
    "    'financial-news-sentiment/data/NVDA_historical_data.csv',\n",
    "    'financial-news-sentiment/data/TSLA_historical_data.csv',\n",
    "    'financial-news-sentiment/META_historical_data.csv'\n",
    "]\n",
    "\n",
    "# Combine all stock data into one DataFrame\n",
    "dfs = []\n",
    "for ticker, path in zip(tickers, file_paths):\n",
    "    temp_df = pd.read_csv(path)\n",
    "    temp_df['ticker'] = ticker\n",
    "    dfs.append(temp_df)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Analyst ratings\n",
    "Ddf = pd.read_csv('financial-news-sentiment/data/raw_analyst_ratings.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\hp\\Downloads\\Telegram Desktop\\10Academy-Week1-FNSPID\\.venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.11.0)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/hp/Downloads/Telegram Desktop/10Academy-Week1-FNSPID/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()\n",
    "df['ticker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "# Set plot style\n",
    "sns.set_theme()\n",
    "sns.set_palette('husl')\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "# Set plot style\n",
    "sns.set_theme()\n",
    "sns.set_palette('husl')\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "# Set plot style\n",
    "sns.set_theme()\n",
    "sns.set_palette('husl')\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text length analysis\n",
    "df['headline_length'] = df['headline'].apply(len)\n",
    "\n",
    "# Basic statistics\n",
    "headline_stats = df['headline_length'].describe()\n",
    "headline_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publisher analysis\n",
    "publisher_counts = df['publisher'].value_counts()\n",
    "top_publishers = publisher_counts.head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_publishers.plot(kind='bar')\n",
    "plt.title('Top 10 Most Active Publishers')\n",
    "plt.xlabel('Publisher')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Daily publication frequency\n",
    "daily_frequency = df.groupby(df['date'].dt.date).size()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "daily_frequency.plot()\n",
    "plt.title('Daily Publication Frequency')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Text preprocessing\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return tokens\n",
    "\n",
    "# Process all headlines\n",
    "all_tokens = []\n",
    "for headline in df['headline']:\n",
    "    tokens = preprocess_text(headline)\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "# Most common words\n",
    "word_counts = Counter(all_tokens)\n",
    "common_words = word_counts.most_common(20)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar([word[0] for word in common_words], [word[1] for word in common_words])\n",
    "plt.title('Top 20 Most Common Words in Headlines')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
